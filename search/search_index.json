{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Welcome to RH 1.5D's documentation!","text":"<p>Welcome to the RH 1.5D documentation. Head over to the Introduction or browse the different sections.</p>"},{"location":"bugs/","title":"Known bugs and limitations","text":"<p>RH 1.5D is always evolving, and there are likely to be bugs and limitations. If you find bugs, please file them as issues on github. They will be dealt with as time permits.</p>"},{"location":"bugs/#current-issues","title":"Current issues","text":"<ul> <li>Check the github RH issues     page for an updated list.</li> <li>If the <code>scratch</code> or <code>output</code> directories are not present, the code     will crash. The error message is not very clear.</li> <li>In <code>keyword.input</code>, if one sets a <code>SNAPSHOT</code> value to be more than     what is in the atmosphere file, the code will stop with an error     message: <code>Index exceeds dimension bound</code>. This error should be made     more clear.</li> <li>The atom files must not end with a blank line, otherwise <code>gencol</code>     will fail and the program stops.</li> <li>Line buffered or full buffered log options still require the user to     change the source code.</li> <li>Depth refinement fails in some cases due to problems caused by cubic     interpolation artefacts.</li> <li>Using more than 4000 cores and writing full output may cause I/O     slowdowns and Lustre contention in some systems.</li> </ul>"},{"location":"bugs/#planned-features","title":"Planned features","text":"<ul> <li>Support for multiple snapshots in the output files.</li> <li><code>pool</code> mode be more flexible, with the possibility of     several <code>overlord</code> nodes, useful for running with more     than 4000 processes.</li> <li>More flexible control of what output is written.</li> </ul>"},{"location":"cmd/","title":"Command line tools","text":"<p>Two useful command line tools that come with HDF5 are h5dump and h5repack.</p> <p><code>h5dump</code> can be used with the <code>-H</code> option to look at the header of a file: see the dimensions, variables, groups. It can also be used to print a text version of any variable in an HDF5 file (e.g. this can be redirected to a text file). When printing a variable (dataset in HDF5) one uses the option <code>-d variable</code>, and the resulting output is the same as in the <code>-H</code> mode, with the variable printed at the end. The NetCDF ncdump program offers an even clearer look into the file (e.g. used with the <code>-h</code> option to print out the header).</p> <p>The <code>h5repack</code> program can be used to copy and modify the parameters of HDF5 files. It can convert the files between different format versions, compress variables, etc. Of particular importance is the option for rechunking a file. Chunking in HDF5 files can be used to improve performance by changing the disk structures to improve different read patterns. It is analogous to fully or partially transposing the variables along certain dimensions.</p> <p>See also</p> <p>h5dump guide: Detailed information about <code>h5dump</code>.</p> <p>h5repack guide: Detailed information about <code>h5repack</code>.</p> <p>Chunking in HDF5: Description on the advantages of chunking.</p>"},{"location":"helita/","title":"<code>helita</code> interface","text":"<p>The helita Python package contains several routines to interface with RH 1.5D. Installation instructions are available in its website.</p>"},{"location":"helita/#reading-and-writing-input-files","title":"Reading and writing input files","text":""},{"location":"helita/#writing-atmosphere-files","title":"Writing atmosphere files","text":"<p>The <code>rh15d</code> module in <code>helita.sim</code> contains a function to write an input atmosphere in RH 1.5D format, assuming the user already has the required data to write at hand. Its function definition is:</p> <pre><code>def make_xarray_atmos(outfile, T, vz, z, nH=None, x=None, y=None, Bz=None, By=None,\n                      Bx=None, rho=None, ne=None, vx=None, vy=None, vturb=None,\n                      desc=None, snap=None, boundary=None, append=False):\n    \"\"\"\n    Creates HDF5 input file for RH 1.5D using xarray.\n\n    Parameters\n    ----------\n    outfile : string\n        Name of destination. If file exists it will be wiped.\n    T : n-D array\n        Temperature in K. Its shape will determine the output\n        dimensions. Shape is generally (nt, nx, ny, nz), but any\n        dimensions except nz can be omitted. Therefore the array can\n        be 1D, 2D, or 3D, 4D but ultimately will always be saved as 4D.\n    vz : n-D array\n        Line of sight velocity in m/s. Same shape as T.\n    z : n-D array\n        Height in m. Can have same shape as T (different height scale\n        for each column) or be only 1D (same height for all columns).\n    nH : n-D array, optional\n        Hydrogen populations in m^-3. Shape is (nt, nhydr, nx, ny, nz),\n        where nt, nx, ny can be omitted but must be consistent with\n        the shape of T. nhydr can be 1 (total number of protons) or\n        more (level populations). If nH is not given, rho must be given!\n    ne : n-D array, optional\n        Electron density in m^-3. Same shape as T.\n    rho : n-D array, optional\n        Density in kg m^-3. Same shape as T. Only used if nH is not given.\n    vx : n-D array, optional\n        x velocity in m/s. Same shape as T. Not in use by RH 1.5D.\n    vy : n-D array, optional\n        y velocity in m/s. Same shape as T. Not in use by RH 1.5D.\n    vturb : n-D array, optional\n        Turbulent velocity (Microturbulence) in km/s. Not usually needed\n        for MHD models, and should only be used when a depth dependent\n        microturbulence is needed (constant microturbulence can be added\n        in RH).\n    Bx : n-D array, optional\n        Magnetic field in x dimension, in Tesla. Same shape as T.\n    By : n-D array, optional\n        Magnetic field in y dimension, in Tesla. Same shape as T.\n    Bz : n-D array, optional\n        Magnetic field in z dimension, in Tesla. Same shape as T.\n    x : 1-D array, optional\n        Grid distances in m. Same shape as first index of T.\n    y : 1-D array, optional\n        Grid distances in m. Same shape as second index of T.\n    x : 1-D array, optional\n        Grid distances in m. Same shape as first index of T.\n    snap : array-like, optional\n        Snapshot number(s).\n    desc : string, optional\n        Description of file\n    boundary : Tuple, optional\n        Tuple with [bottom, top] boundary conditions. Options are:\n        0: Zero, 1: Thermalised, 2: Reflective.\n    append : boolean, optional\n        If True, will append to existing file (if any).\n    \"\"\"\n</code></pre> <p>Note that while in this routine the writing of the hydrogen populations is optional (they can be derived from the mass density, if available), RH 1.5D does not support this yet.</p> <p>Note</p> <p>The variables passed to <code>make_xarray_atmos</code> must be consistent with the height scale. The first height index must be the top of the atmosphere (closest to observer), and the height scale must be strictly decreasing.</p>"},{"location":"helita/#reading-atmosphere-files","title":"Reading atmosphere files","text":"<p>Once written, the input atmosphere files can be read in Python with <code>xarray</code>, and do not require <code>helita</code>. For example:</p> <pre><code>&gt;&gt;&gt; import xarray\n&gt;&gt;&gt; atmos = xarray.open_dataset('my_atmos.hdf5')\n&gt;&gt;&gt; atmos\n&lt;xarray.Dataset&gt;\nDimensions:               (depth: 82, nhydr: 6, snapshot_number: 1, x: 5, y: 5)\nCoordinates:\n  * x                     (x) int64 0 1 2 3 4\n  * y                     (y) int64 0 1 2 3 4\n    z                     (snapshot_number, depth) float32 ...\n  * snapshot_number       (snapshot_number) int32 0\nDimensions without coordinates: depth, nhydr\nData variables:\n    temperature           (snapshot_number, x, y, depth) float32 ...\n    velocity_z            (snapshot_number, x, y, depth) float32 ...\n    electron_density      (snapshot_number, x, y, depth) float64 ...\n    hydrogen_populations  (snapshot_number, nhydr, x, y, depth) float32 ...\n    velocity_turbulent    (snapshot_number, x, y, depth) float32 ...\nAttributes:\n    comment:          Created with make_xarray_atmos on 2018-01-25 15:28:10.4...\n    boundary_top:     0\n    boundary_bottom:  1\n    has_B:            0\n    description:      FAL C model with 82 depth points replicated to 5x5 colu...\n    nx:               5\n    ny:               5\n    nz:               82\n    nt:               1\n</code></pre> <p>The amount of detail loaded by <code>xarray</code> will depend how the atmosphere was written. Older atmosphere files may not have as much verbose attributes or labeled coordinates (especially if written by plain HDF5 with no attaching of dimension scales), but they are still valid. Older netCDF atmospheres should work fine with <code>xarray</code>.</p> <p>It is also possible to modify the data with <code>xarray</code>, and saving and updated atmosphere is done via the <code>to_netcdf()</code> method:</p> <pre><code>&gt;&gt;&gt; atmos.to_netcdf(\"newfile.hdf5\", format='NETCDF4')\n</code></pre> <p>Be sure to use <code>format='NETCDF4'</code> so that the file is internally HDF5!</p>"},{"location":"helita/#writing-wavelength-files","title":"Writing wavelength files","text":"<p>Another utility function in <code>rh15d.py</code> is <code>make_wave_file</code>. This creates an RH wavelength file (to be used with the option <code>WAVETABLE</code> in <code>keyword.input</code>) that contains additional wavelengths to be calculated. The function's usage is documented in its function call:</p> <pre><code>def make_wave_file(outfile, start=None, end=None, step=None, new_wave=None,\n                   ewave=None, air=True):\n   \"\"\"\n   Writes RH wave file (in xdr format). All wavelengths should be in nm.\n\n   Parameters\n   ----------\n   start: number\n       Starting wavelength.\n   end: number\n       Ending wavelength (non-inclusive)\n   step: number\n       Wavelength separation\n   outfile: string\n       Name of file to write.\n   ewave: 1-D array, optional\n       Array of existing wavelengths. Program will make discard points\n       to make sure no step is enforced using these points too.\n   air: boolean, optional\n       If true, will at the end convert the wavelengths into vacuum\n       wavelengths.\n   \"\"\"\n</code></pre> <p>You can either supply an array with the wavelengths, or give a range of wavelengths and a fixed spacing, e.g.:</p> <pre><code>&gt;&gt;&gt; from helita.sim import rh15d\n&gt;&gt;&gt; rr = rh15d.Rh15dout()\n# this will write wavelenghts from 650 to 650 nm, 0.01 nm spacing:\n&gt;&gt;&gt; rh15d.make_wave_file('my.wave', 650, 660, 0.01)\n# this will write an existing array \"my_waves\", if it exists\n&gt;&gt;&gt; rh15d.make_wave_file('my.wave', ewave=my_waves)\n</code></pre>"},{"location":"helita/#reading-output-files","title":"Reading output files","text":"<p>The main class to read the output is called <code>Rh15dout</code>. It uses <code>xarray</code> under the hood and populates an object with all the different datasets. It can be initiated in the following way:</p> <pre><code>&gt;&gt;&gt; from helita.sim import rh15d\n&gt;&gt;&gt; rr = rh15d.Rh15dout()\n--- Read ./output_aux.hdf5 file.\n--- Read ./output_indata.hdf5 file.\n--- Read ./output_ray.hdf5 file.\n</code></pre> <p>By default, it will look for the three files in the directory specified as main argument (defaults to current directory). Additionally, the method <code>read_group(infile)</code> can be used to manually load the <code>output_aux.hdf5</code> or <code>output_indata.hdf5</code> and the method and <code>read_ray(infile)</code> can be used to manually load the <code>output_ray.hdf5</code> file. The variables themselves are not read into memory, but are rather a memmap object (file pointer; only read when needed) that <code>xarray</code> opens.</p> <p>After loading the files, the <code>Rh15dout</code> instance loads each file as an <code>xarray</code> dataset with the base name of each group (e.g. <code>ray</code>, <code>atmos</code>, <code>atom_CA</code>, <code>mpi</code>).The <code>ray</code> attribute contains the same dataset as shown in the <code>xarray</code> example above.</p> <p>The attributes of each file are still accessible under the attributes of each object, e.g.:</p> <pre><code>&gt;&gt;&gt; rr.ray.creation_time\n'2018-01-10T16:16:42+0100'\n&gt;&gt;&gt; rr.atmos.nrays\n5\n&gt;&gt;&gt; rr.mpi.nprocesses\n2048\n</code></pre> <p>With <code>xarray</code> it is easy to quickly inspect and plot different quantities. For example, to plot the intensity at <code>(x, y) = (0, 0)</code>:</p> <pre><code>&gt;&gt;&gt; rr.ray.intensity[0, 0].plot()\n</code></pre> <p>Or the intensity at a fixed wavelength:</p> <pre><code>&gt;&gt;&gt; rr.ray.intensity.sel(wavelength=279.55, method='nearest').plot()\n</code></pre> <p>(This only shows a 2D image if you calculated the intensity from a 3D model, otherwise an histogram or line plot is shown.)</p>"},{"location":"helita/#visualisation-and-notebooks","title":"Visualisation and notebooks","text":"<p><code>helita</code> includes a visualisation module, <code>helita.sim.rh15d_vis</code>, with widgets that are meant to be used inside the Jupyter notebook. To use these, you will need to install not only <code>helita</code> but also the Matplotlib Jupyter Extension and the IPython widgets for Jupyter. If you have Anaconda, both can be installed with conda:</p> <pre><code>conda install -c conda-forge ipywidgets ipympl widgetsnbextension\njupyter nbextension enable --py widgetsnbextension\n</code></pre> <p>You can also install them with <code>pip</code> (check their pages for details).</p> <p>Currently we have the following Jupyter notebooks for visualisation of RH 1.5D output:</p> <ul> <li>Basic     output</li> <li>Visualisation     widgets</li> </ul> <p>To use the above notebooks, you need to have run RH 1.5D and have the output files ready!</p> <p>You can also explore the input atmosphere files with the Jupyter widget <code>rh15d_vis.InputAtmosphere</code> in <code>helita</code>:</p> <pre><code>&gt;&gt;&gt; from helita.sim import rh15d_vis\n&gt;&gt;&gt; rh15d_vis.InputAtmosphere('my_atmos.hdf5')\n</code></pre>"},{"location":"input/","title":"Input files","text":""},{"location":"input/#configuration-files","title":"Configuration files","text":"<p>The configuration of an RH 1.5D is made primarily through several text files that reside in the run directory. The main file is <code>keyword.input</code>. All the other files and their locations are specified in <code>keyword.input</code>. The source tree contains a sample <code>rh/rh15d/run/</code> directory with the following typically used configuration files:</p> File Description <code>atoms.input</code> Lists the atom files to be used <code>keyword.input</code> Main configuration file <code>kurucz.input</code> Contains list of line lists to be used <code>molecules.input</code> Lists the molecule files to be used <code>ray.input</code> Selects output mu and wavelengths for detailed output <p>The <code>kurucz.input</code> and the <code>molecules.input</code> files are identical under RH, so we refer to the RH manual for more information about them. Most of the other files behave very similarly in RH and RH 1.5D, with a few differences.</p> <p>The <code>atoms.input</code> file is identical in RH, but it can also have a new starting solution, <code>ESCAPE_PROBABILITY</code>.</p> <p>The <code>keyword.input</code> file functions in very much the same manner under RH and RH 1.5D. The main difference is that there are new options for the 1.5D version, and some options should not be used.</p> <p>The new <code>keyword.input</code> options for the 1.5D version are:</p> Name Default value Description <code>SNAPSHOT</code> <code>0</code> Snapshot index from the atmosphere file. <code>X_START</code> <code>0</code> Starting column in the x direction. If &lt; 0, will be set to 0. <code>X_END</code> <code>-1</code> Ending column in the x direction. If &lt;= 0, will be set to <code>NX</code> in the atmosphere file. <code>X_STEP</code> <code>1</code> How many columns to sample in the y direction. If &lt; 1, will be set to 1. <code>Y_START</code> <code>0</code> Starting column in the y direction. If &lt; 0, will be set to 0. <code>Y_END</code> <code>-1</code> Ending column in the y direction. If &lt;= 0, will be set to <code>NY</code> in the atmosphere file. <code>Y_STEP</code> <code>1</code> How many columns to sample in the y direction. If &lt; 1, will be set to 1. <code>15D_WRITE_POPS</code> <code>FALSE</code> If <code>TRUE</code>, will write the level populations (including LTE) for each active atom to <code>output_aux.hdf5</code>. <code>15D_WRITE_RRATES</code> <code>FALSE</code> If <code>TRUE</code>, will write the radiative rates (lines and continua) for each active atom to <code>output_aux.hdf5</code>. <code>15D_WRITE_CRATES</code> <code>FALSE</code> If <code>TRUE</code>, will write the collisional rates for each active atom to <code>output_aux.hdf5</code>. <code>15D_WRITE_TAU1</code> <code>FALSE</code> If <code>TRUE</code>, will write the height of tau=1 to <code>output_ray.hdf5</code>, for all wavelengths (this takes up as much space as the intensity). <code>15D_RERUN</code> <code>FALSE</code> If <code>TRUE</code>, will rerun for non-converged columns. <code>15D_DEPTH_ZCUT</code> <code>TRUE</code> If <code>TRUE</code>, will perform a cut in z for  points above a threshold temperature <code>15D_TMAX_CUT</code> <code>-1</code> Threshold temperature (in K) over which the above depth cut ids made. If &lt; 0, no temperature cut will be made. <code>15D_DEPTH_REFINE</code> <code>FALSE</code> If <code>TRUE</code>, will perform an optimisation of the depth scale, based on optical depth, density and temperature gradients. <code>BACKGR_IN_MEM</code> <code>FALSE</code> If <code>TRUE</code>, will keep background opacity coefficients in memory instead of scratch files on disk. <code>BARKLEM_DATA_DIR</code> <code>../../Atoms</code> Directory where the <code>Barklem_*data.dat</code> data files are saved. <code>COLLRAD_SWITCH</code> <code>0.0</code> Defines if collisional radiative switching is on. If &lt; 0, switching parameter is constant (and equal to <code>COLLRAD_SWITCH_INI</code>). If = 0, no collisional radiative switching. If &gt; 0, collisional radiative switching decreases by <code>COLLRAD_SWITCH</code> per log decade,  starting with <code>COLLRAD_SWITCH_INI</code>. <code>COLLRAD_SWITCH_INIT</code> <code>1.0</code> Initial increment for collisional-radiative  switching <code>LIMIT_MEMORY</code> <code>FALSE</code> If <code>TRUE</code>, will not keep several large  arrays in memory but rather save them to scratch files. Not recommended unless memory usage is critical. <code>N_PESC_ITER</code> <code>3</code> Number of escape probability iterations, if any atoms have it as initial solution. <code>PRD_SWITCH</code> <code>0.0</code> If &gt; 0, the PRD effects will be added gradually, converging to the full PRD solution in <code>1/sqrt(PRD_SWITCH)</code> iterations. <code>PRDH_LIMIT_MEM</code> <code>FALSE</code> If <code>TRUE</code> and using <code>PRD_ANGLE_APPROX</code>, will not keep in memory quantities necessary to calculate the current PRD weights, but rather calculate them again. Will affect the performance, so should be used only when necessary. <code>S_INTERPOLATION</code> <code>LINEAR</code> Type of source function interpolation to use in formal solver. Can be <code>LINEAR</code>, <code>BEZIER</code>, <code>BEZIER3</code> or <code>CUBIC_HERMITE</code>. <code>S_INTERPOLATION_STOKES</code> <code>DELO_PARABOLIC</code> Type of source function interpolation to  use in formal solver for polarised cases. Can be <code>DELO_PARABOLIC</code> or <code>DELO_BEZIER3</code>, see<sup>1</sup> . <code>VTURB_MULTIPLIER</code> <code>1.0</code> Atmospheric <code>vturb</code> will be multiplied by this value <code>VTURB_ADD</code> <code>0.0</code> Value to be added to atmospheric <code>vturb</code> <p>The <code>X_START</code>, <code>X_END</code>, and <code>X_STEP</code> keywords (and the equivalent for the y direction) define which columns of the atmosphere file are going to be run. They can be used to calculate only a specific region. RH 1.5D chooses the columns to calculate using the <code>(start, end, step)</code> parameters as in the <code>range()</code> function in Python: the result is <code>[start, start + step, start + 2 * step, ...]</code>. The last element is the largest <code>start + i * step</code> less than <code>end</code>. This means that the numbers given by <code>X_END</code> and <code>Y_END</code> are not inclusive (e.g. if <code>nx = 50</code> and <code>X_END = 49</code>, the column with the index 49 will not be calculated). One must set <code>X_END = nx</code> to calculate all the columns.</p> <p>The following options have a different meaning under RH 1.5D:</p> Name Default value Description <code>PRD_ANGLE_DEP</code> <code>PRD_ANGLE_INDEP</code> This keyword is no longer boolean. To accommodate for new options, it now takes the values <code>PRD_ANGLE_INDEP</code> for  angle-independent PRD, <code>PRD_ANGLE_DEP</code> for angle-dependent PRD, and <code>PRD_ANGLE_APPROX</code> for the approximate angle-dependent scheme of Leenaarts et al. (2012)<sup>2</sup> . <code>BACKGROUND_FILE</code> This keyword is no longer the name of the  background file, but the prefix of the background files. There will be one file per process, and the filenames are this prefix plus <code>_i.dat</code>, where <code>i</code> is the process number. <code>STOKES_INPUT</code> This option is not used in RH 1.5D because  the magnetic fields are now written to the atmosphere file. However, it must be set to any string if one is using any <code>STOKES_MODE</code> other than <code>NO_STOKES</code> (RH  won't read B otherwise). <p>And the following options are valid for RH but may not work with RH 1.5D:</p> Name Default value Description <code>LIMIT_MEMORY</code> <code>FALSE</code> This option has not been tested and may not work well with RH 1.5D. <code>PRINT_CPU</code> <code>FALSE</code> This option does not work with RH 1.5D and should always be <code>FALSE</code>. <code>N_THREADS</code> <code>0</code> Thread parallelism will not work with RH 1.5D. This option should always be <code>0</code> or<code>1</code>. <p>The <code>ray.input</code> has the same structure in RH1D and RH 1.5D. In RH it is used as input for the <code>solveray</code> program, but in RH 1.5D it is used for the main program. It should contain the following:</p> <pre><code>1.00\nNsource\n</code></pre> <p>The first line is the <code>mu</code> angle for the output ray, and it should always be 1.00. The second line is <code>Nsource</code>, the number of wavelengths for which detailed output (typically source function, opacity, and emissivities) will be written. If <code>Nsource &gt; 0</code>, it should be followed in the same line by the indices of the wavelengths (e.g. <code>0 2 10 20</code>).</p>"},{"location":"input/#atom-and-molecule-files","title":"Atom and molecule files","text":"<p>The atom and molecule files have the same format as in RH. In the <code>rh/Atoms</code> and <code>rh/Molecules</code> directories there are a few sample files. They are read by the procedures in <code>readatom.c</code> and <code>readmolecule.c</code>. The atom files have the following basic structure:</p> Input Format <code>ID</code> (A2). Two-character atom identifier. <code>Nlevel Nline Ncont Nfixed</code> (4I). Number of levels, lines,  continua, and fixed radiation temperature transitions. <code>level_entries</code> Nlevel * (2F, A20, I) <code>line entries</code> Nline * (2I, F, A, I, A, 2F, A, 6F) <code>continuum_entries</code> Ncont * (I, I, F, I, A, F) <code>fixed_entries</code> Ncont * (2I, 2F, A)"},{"location":"input/#atmosphere-files","title":"Atmosphere files","text":"<p>The atmosphere files for RH 1.5D are a significant departure from RH. They are written in the flexible and self-describing HDF5 format. They can be written with any version, except the 1.10.x development branch.</p> <p>The atmosphere files contain all the atmospheric variables necessary for RH 1.5D, and they may contain one or more simulation snapshots. The basic dimensions of the file are:</p> <code>nt</code> Number of snapshots. <code>nx</code> Number of x points <code>ny</code> Number of y points. <code>nz</code> Number of depth points. <code>nhydr</code> Number of hydrogen levels. <p>While strictly 3D atmosphere files, 2D and 1D snapshots can also be used provided that one or both of <code>nx</code> and <code>ny</code> are equal to 1.</p> <p>Note</p> <p>The atmosphere variables must be written to the file in a particular way. They should be written in a height grid (meaning the top of the atmosphere has a larger value of <code>z</code>), and must start from the top (meaning that the first height index of the arrays must be the TOP of the atmosphere). Failure to follow these two rules can either lead to RH aborting a run, or worse, getting wrong results without a clear error message.</p> <p>The atmosphere file can contain the following variables:</p> Name Dimensions Units Notes <code>B_x</code> <code>(nt, nx, ny, nz)</code> T Magnetic field x component. Optional <code>B_y</code> <code>(nt, nx, ny, nz)</code> T Magnetic field y component. Optional <code>B_z</code> <code>(nt, nx, ny, nz)</code> T Magnetic field z component. Optional <code>electron_density</code> <code>(nt, nx, ny, nz)</code> m<sup>-3</sup> Optional. <code>hydrogen_populations</code> <code>(nt, nhydr, nx, ny, nz)</code> m<sup>-3</sup> <code>nhydr</code> must correspond to the number of levels  in the hydrogen atom used. If <code>nhydr=1</code>, this  variable should contain the total number of hydrogen atoms (in all levels), and LTE populations will be calculated. <code>snapshot_number</code> <code>(nt)</code> None The snapshot number is an array of integers to identify each snapshot in the output files. <code>temperature</code> <code>(nt, nx, ny, nz)</code> K <code>velocity_z</code> <code>(nt, nx, ny, nz)</code> m s<sup>-1</sup> Vertical component of velocity. Positive velocity is upflow. <code>velocity_turbulent</code> <code>(nt, nx, ny, nz)</code> m s<sup>-1</sup> Turbulent velocity (microturbulence). <code>z</code> <code>(nt, nx, ny, nz)</code> or  <code>(nt, nz)</code> m Height grid. Can vary with column and snapshot. First <code>nz</code> index is top of the atmosphere (closest to observer). <p>Any other variable in the file will not be used. In addition, the atmosphere file must have a global attribute called <code>has_B</code>. This attribute should be 1 when the magnetic field variables are present, and 0 otherwise. Also recommended, but optional, is a global attribute called <code>description</code> with a brief description of the atmosphere file (e.g. how and from they were generated).</p> <p>Note</p> <p>Variables in the atmosphere files can be compressed (zlib or szip), but compression is not recommended for performance reasons.</p> <p>As HDF5 files, the contents of the atmosphere files can be examined with the <code>h5dump</code> utility. To see a summary of what's inside a given file, one can do:</p> <pre><code>h5dump -H atmosfile\n</code></pre> <p>Here is the output of the above for a sample file:</p> <pre><code>HDF5 \"example.hdf5\" {\nGROUP \"/\" {\n   ATTRIBUTE \"boundary_bottom\" {\n      DATATYPE  H5T_STD_I64LE\n      DATASPACE  SCALAR\n   }\n   ATTRIBUTE \"boundary_top\" {\n      DATATYPE  H5T_STD_I64LE\n      DATASPACE  SCALAR\n   }\n   ATTRIBUTE \"description\" {\n      DATATYPE  H5T_STRING {\n         STRSIZE H5T_VARIABLE;\n         STRPAD H5T_STR_NULLTERM;\n         CSET H5T_CSET_UTF8;\n         CTYPE H5T_C_S1;\n      }\n      DATASPACE  SCALAR\n   }\n   ATTRIBUTE \"has_B\" {\n      DATATYPE  H5T_STD_I64LE\n      DATASPACE  SCALAR\n   }\n   ATTRIBUTE \"nhydr\" {\n      DATATYPE  H5T_STD_I64LE\n      DATASPACE  SCALAR\n   }\n   ATTRIBUTE \"nx\" {\n      DATATYPE  H5T_STD_I64LE\n      DATASPACE  SCALAR\n   }\n   ATTRIBUTE \"ny\" {\n      DATATYPE  H5T_STD_I64LE\n      DATASPACE  SCALAR\n   }\n   ATTRIBUTE \"nz\" {\n      DATATYPE  H5T_STD_I64LE\n      DATASPACE  SCALAR\n   }\n   DATASET \"electron_density\" {\n      DATATYPE  H5T_IEEE_F64LE\n      DATASPACE  SIMPLE { ( 1, 512, 512, 425 ) / ( H5S_UNLIMITED, 512, 512, 425 ) }\n   }\n   DATASET \"hydrogen_populations\" {\n      DATATYPE  H5T_IEEE_F32LE\n      DATASPACE  SIMPLE { ( 1, 6, 512, 512, 425 ) / ( H5S_UNLIMITED, 6, 512, 512, 425 ) }\n   }\n   DATASET \"snapshot_number\" {\n      DATATYPE  H5T_STD_I32LE\n      DATASPACE  SIMPLE { ( 1 ) / ( 1 ) }\n   }\n   DATASET \"temperature\" {\n      DATATYPE  H5T_IEEE_F32LE\n      DATASPACE  SIMPLE { ( 1, 512, 512, 425 ) / ( H5S_UNLIMITED, 512, 512, 425 ) }\n   }\n   DATASET \"velocity_z\" {\n      DATATYPE  H5T_IEEE_F32LE\n      DATASPACE  SIMPLE { ( 1, 512, 512, 425 ) / ( H5S_UNLIMITED, 512, 512, 425 ) }\n   }\n   DATASET \"x\" {\n      DATATYPE  H5T_IEEE_F32LE\n      DATASPACE  SIMPLE { ( 512 ) / ( 512 ) }\n   }\n   DATASET \"y\" {\n      DATATYPE  H5T_IEEE_F32LE\n      DATASPACE  SIMPLE { ( 512 ) / ( 512 ) }\n   }\n   DATASET \"z\" {\n      DATATYPE  H5T_IEEE_F32LE\n      DATASPACE  SIMPLE { ( 1, 425 ) / ( H5S_UNLIMITED, 425 ) }\n   }\n}\n}\n</code></pre> <p>All the floating point variables can be either double or single precision.</p>"},{"location":"input/#line-lists-and-wavelength-files","title":"Line lists and wavelength files","text":"<p>Other auxiliary files that can be used are line lists files and wavelength files.</p> <p>The line list files are used to include additional lines not included in the different atoms. These lines will be treated in LTE. The line lists are specified in the <code>kurucz.input</code> file (one per line), and have the Kurucz line list format (link).</p> <p>Just adding new transitions doesn't mean that they will be included in the synthetic spectra. The extra lines will only be included in the existing wavelength grid, which depends on the active atoms used. The calculation of additional wavelengths can be forced by using a wavelength file. This file is specified in <code>keyword.input</code> using the keyword <code>WAVETABLE</code>. The format is a binary XDR file. Its contents are, in order: the number of new wavelengths (1 XDR int), vacuum wavelength values (XDR doubles).</p> <ol> <li> <p>de la Cruz Rodr\u00edguez, J.; Piskunov, N. 2013, ApJ, 764, 33, ADS link.\u00a0\u21a9</p> </li> <li> <p>Leenaarts, J., Pereira, T. M. D., &amp; Uitenbroek, H. 2012, A&amp;A, 543, A109, ADS link.\u00a0\u21a9</p> </li> </ol>"},{"location":"installation/","title":"Installation","text":""},{"location":"installation/#getting-the-code","title":"Getting the code","text":"<p>The code is available on a git repository, hosted on github: https://github.com/ita-solar/rh. If you don't have git installed and just want to get started, the easiest way is to download a zip file with the latest revision: https://github.com/ita-solar/rh/archive/master.zip. If you have git installed and would like to be up-to-date with the repository, you can do a git clone:</p> <pre><code>git clone https://github.com/ita-solar/rh.git\n</code></pre> <p>or using SSH:</p> <pre><code>git clone git@github.com:ita-solar/rh.git\n</code></pre> <p>Whether you unpack the zip file or do one of the above it will create a directory called <code>rh</code> in your current path. This directory will have the following subdirectories:</p> Directory Contents rh Main RH source rh/Atmos Used to keep atmosphere files rh/Atoms_example Used to keep atom files, line and wavelength lists (example) rh/idl Old RH IDL routines, not used rh/Molecules Used to keep molecule files rh/python Utility Python programs rh/rh15d. Source files for RH 1.5D rh/rhf1d Source files for 1D geometry  deprecated, do not use rh/rhsphere Source files for spherical geometry  deprecated, do not use rh/tools Associate C programs for RH, not tested. <p>Warning</p> <p>The source code directories for other geometries (rhf1d, rhsphere) are still in the code tree, but they are deprecated and will be removed soon. With the latest changes related to rh15d, they are not guaranteed to work or even run. Do not use.</p>"},{"location":"installation/#dependencies","title":"Dependencies","text":""},{"location":"installation/#hdf5","title":"HDF5","text":"<p>RH 1.5D makes use of the HDF5 library to read the atmosphere files and write the output. It is not possible to run the code without this library. RH 1.5D requires HDF5 version 1.8.1 or newer (including versions 1.10.x).</p> <p>Info</p> <p>RH 1.5D previously made use of the netCDF4 library for its output (which in turn also required HDF5). The latest changes mean RH 1.5D needs only HDF5. Because netCDF4 files are also HDF5 files, the output is still readable in the same way as before and input files in netCDF version 4 format can still be read in the same way by RH 1.5D. If you used input atmospheres in netCDF version 3 format, then these will have to be converted to HDF5. It is recommended that new atmosphere files be created in HDF5 only.</p> <p>Because HDF5 is commonly used in high-performance computing, many supercomputers already have them available. Here are a few setups for different supercomputers:</p> <p>Betzy:</p> <pre><code>module load iompi/2022a HDF5/1.12.2-iompi-2022a\n</code></pre> <p>Fram:</p> <pre><code>module load HDF5/1.8.19-intel-2018a intel/2018a\n</code></pre> <p>Pleiades:</p> <pre><code>module load hdf5/1.8.18_mpt\n</code></pre> <p>Vilje:</p> <pre><code>module load intelcomp/18.0.1 mpt/2.14 hdf5/1.8.19\n</code></pre> <p>Hexagon:</p> <pre><code>module load cray-hdf5-parallel\n</code></pre> <p>and at ITA's Linux system:</p> <pre><code>module load intel/oneapi compiler/latest mpi/latest hdf5/Intel/1.14.3\n</code></pre>"},{"location":"installation/#mpi","title":"MPI","text":"<p>You need MPI to run RH 1.5D. In supercomputers and clusters these are provided, but for your workstation or laptop you may need to install manually both MPI and HDF5 (with parallel support). If you have an existing conda or mamba installation, it should be possible to install compilers, MPI libraries, and HDF5 parallel. For example, the following will install the latest version of HDF5 with OpenMPI as the MPI library:</p> <pre><code>conda install -c conda-forge 'hdf5=*=*openmpi*'\n</code></pre> <p>This will install HDF5 to the same directory of your python environment (files under <code>lib/</code> and <code>bin/</code>). This setup has been tested on macOS with Apple Silicon, and works for RH 1.5D. However, packages may change and you may need to specify another way. Installing HDF5 via the system package manager (e.g. apt-get in Linux) is not recommended, since those HDF5 builds will probably not have parallel support.</p> <p>If installing binaries fails, the safest bet is to download and compile HDF5 from the source, enabling parallel builds in the <code>./configure</code> script, e.g.:</p> <pre><code>./configure (...) --enable-parallel\n</code></pre>"},{"location":"installation/#compilation","title":"Compilation","text":"<p>Compilation of RH 1.5D consists of two steps:</p> <ol> <li>Compilation of the geometry-independent main libraries (<code>librh.a</code>     and <code>librh_f90.a</code>)</li> <li>Compilation of the <code>rh15d_mpi</code> tree and main binaries</li> </ol> <p>RH 1.5D has been compiled in a variety of architectures and compilers, including gcc, the Intel compilers, and clang. As for MPI implementations, it has been tested with SGI's mpt, OpenMPI, mpich, mvapich, and Intel's MPI.</p>"},{"location":"installation/#makefile-configuration","title":"Makefile configuration","text":"<p>RH 1.5D does not automatically look for the compilers and libraries. You need to tell RH which compilers to use and where to find the HDF5 library by editing the file <code>rh/Makefile.config</code>. This file is also used to set up any additional compiler or linker flags, if appropriate. Changes to any other Makefiles are not necessary. It is also no longer necessary to set the environment variables <code>OS</code> and <code>CPU</code>, as in previous versions.</p> <p>For <code>HDF5_DIR</code>, please enter the base directory for the library (not the directory with the lib* files), so that both library and include files are used. In Fram and Hexagon this is already stored in the <code>HDF5_DIR</code> environment variable, so you can comment that line in <code>Makefile.config</code>. If your version of HDF5 was not built as a shared binary, you need to link HDF5 and other used libraries directly (you will need to set at least <code>-lz</code> in <code>LDFLAGS</code>).</p> <p>The following compiler flags are recommended for Betzy:</p> <pre><code>CFLAGS = -O3 -DHAVE_F90 -qopt-prefetch -use-intel-optimized-headers -march=core-avx2 -fp-model source  \nF90FLAGS = -O3 -qopt-prefetch -use-intel-optimized-headers -march=core-avx2 -fp-model source\n</code></pre> <p>And for the ITA linux system (RHEL 9.x):</p> <pre><code>CFLAGS = -O3 -DHAVE_F90 -Wformat  -I/usr/include/tirpc/  -std=gnu89\nF90FLAGS = -O3 -Wformat  -I/usr/include/tirpc/  -std=gnu89\nLDFLAGS = -ltirpc\nHDF5_DIR = /astro/local/hdf5/rhel9/1.14.3/intel/\n</code></pre> <p>There are two steps in the compilation: main libraries and rh15d binaries. To speed up compilation, you can use parallel builds (e.g. <code>make -j8</code>) in all steps of the compilation.</p>"},{"location":"installation/#main-libraries","title":"Main libraries","text":"<p>The common RH files are put in a library under the base directory. After editing <code>Makefile.config</code>, build the main libraries with <code>make</code> on the <code>rh</code> directory. If successful, the compilation will produce the two library files <code>librh.a</code> and <code>librh_f90.a</code>.</p>"},{"location":"installation/#program-binaries","title":"Program binaries","text":"<p>The <code>rh15d</code> contains the source files for the 1.5D version. After compiling the main library, go to that directory and compile the binaries with <code>make</code>. The following executables will be created:</p> File Description <code>rh15d_ray_pool</code> Main RH 1.5D binary, uses a job pool <code>rh15d_ray</code> Alternative RH 1.5D binary. Deprecated. This program runs much slower than <code>rh15d_ray_pool</code> and is kept for backwards compatibility only. Will be removed in a future revision. <code>rh15d_lteray</code> Special binary for running in LTE"},{"location":"installation/#run-directory","title":"Run directory","text":"<p>Once compiled, you can copy or link the binaries to a run directory. This directory will contain all the necessary input files, and it should contain two subdirectories called <code>output</code> and <code>scratch</code>.</p> <p>Warning</p> <p>If the subdirectories <code>output</code> and <code>scratch</code> do not exist in the directory where the code is run, the code will crash with an obscure error message.</p>"},{"location":"introduction/","title":"Introduction","text":""},{"location":"introduction/#what-is-rh-15d","title":"What is RH 1.5D","text":"<p>RH 1.5D is a modified version of the RH radiative transfer code that runs through a 3D/2D/1D atmosphere column-by-column, in the same fashion of rhf1d. It was developed as a way to efficiently run RH column-by-column (1.5D) over large atmospheres, simplifying the output and being able to run in supercomputers. It is MPI-parallel and scales well to at least 10,000 processes.</p> <p>While initially developed as another geometry on the RH tree, the requirements of the parallel version required changes to the RH core tree. Thus, it is more than a [wrapper]{.title-ref} over RH and is distributed with a modified version of RH (see below for differences from RH distributed by Han Uitenbroek).</p>"},{"location":"introduction/#acknowledging-rh-15d","title":"Acknowledging RH 1.5D","text":"<p>If you use RH 1.5D for your work, we would appreciate if you would acknowledge it appropriately in a publication, presentation, poster, or talk. For a publication, this is best done by citing the RH 1.5D (Pereira &amp; Uitenbroek 2015) and RH (Uitenbroek 2001) papers. In addition, if the journal allows it please include a link to its Github repository.</p>"},{"location":"introduction/#what-this-manual-covers","title":"What this manual covers","text":"<p>Because there is much in common with RH, this manual should be seen as an incremental documentation of the 1.5D parallel side. This manual focuses on what is different from RH. Users should refer to the RH documentation by Han Uitenbroek for more detailed information on RH.</p>"},{"location":"introduction/#comparison-with-rh","title":"Comparison with RH","text":"<p>RH 1.5D inherits most of the code base from RH, but some features are new. The code is organised in the same was as the RH source tree, with the routines specific to the 1.5D version residing on a subdirectory <code>rh15d</code> of the <code>rh</code> source tree. In this way, it works similarly to the subdirectories in <code>rh</code> for different geometries. The compilation and linking proceeds as for the other geometries: first the general <code>librh.a</code> library should be compiled, and then the code in <code>rh15d</code> will be compiled and linked to it. The run directory is very similar to that of a given geometry in RH: most of the <code>*.input</code> files are used in the same way.</p> <p>The lists below show a comparison between RH 1.5D and RH for a 1D plane-parallel geometry:</p>"},{"location":"introduction/#commonalities-between-rh-15d-and-rh","title":"Commonalities between RH 1.5D and RH","text":"<ul> <li>Core RH library</li> <li>Structure and location of <code>*.input</code> files (some new options     available)</li> <li>Wavetable, Atom, Molecule, line list, and any other input files     except the atmospheres</li> <li>Directory-level compilation and general structure of run directory     (new subdirectories needed)</li> </ul>"},{"location":"introduction/#what-is-new-in-rh-15d","title":"What is new in RH 1.5D","text":"<ul> <li>MPI-parallelism with dynamic load balancing and efficient I/O</li> <li>Different format of atmosphere files</li> <li>Different formats of output files</li> <li>Select which quantities should be in output</li> <li>New options for <code>keyword.input</code> and <code>atoms.input</code></li> <li>Hybrid angle-dependent PRD mode</li> <li>PRD-switching</li> <li>Option for using escape probability approximation as initial     solution</li> <li>Exclude from the calculations the higher parts of the atmosphere,     above a user-defined temperature threshold</li> <li>Depth scale optimisation</li> <li>Option for cubic Hermite interpolation of source function in formal     solver</li> <li>Option for cubic B\u00e9zier and DELO B\u00e9zier interpolation of source     function in formal solvers, both for polarised and unpolarised light</li> <li>Support for more types of collisional excitations</li> <li>Easy re-run of non-converged columns</li> <li>Option for keeping background opacities in memory and not in disk</li> <li>New analysis suite in Python</li> </ul>"},{"location":"introduction/#what-is-not-supported-in-rh-15d","title":"What is not supported in RH 1.5D","text":"<ul> <li>Currently only a fraction of the RH output is written to disk (to     save space), but more output can be added</li> <li>The old IDL analysis suite does not currently support the new output     format</li> <li><code>solveray</code> is no longer used</li> <li><code>backgrcontr</code> no longer works with the new output</li> <li>Any other geometry aside from 1.5D</li> <li>Continuing old run by reading populations and output files</li> <li>Full Stokes NLTE iterations and background polarisation (might work     with little effort, but has not been tested)</li> <li>Thread parallelisation</li> </ul>"},{"location":"output/","title":"Output file structure","text":""},{"location":"output/#overview","title":"Overview","text":"<p>Output is written into three files: <code>output_aux.hdf5</code>, <code>output_indata.hdf5</code>, and <code>output_ray.hdf5</code>. This is a big departure from RH, which contained several more output files. In particular, RH 1.5D will not write all the information that was written by RH, due to the sheer size it would take for large 3D simulations. The files are written in the machine-independent, self-describing HDF5 format. The contents of the files are organised in groups, variables, and attributes. Groups and variables can be imagined as directories and files in a filesystem. Inside groups, different variables and dimensions can be organised. The content of the output files can vary: some runs will have more detailed information and therefore more variables written to the files.</p> <p>HDF5 is an open, platform-independent format, and therefore interfaces to many programming languages are available. The main interface libraries are available in C, C++, Fortran, and Java. But there are also interfaces for Python (h5py), Julia, IDL (from version 6.2), MATLAB , Octave, Perl, and R.</p> <p>The RH 1.5D output format is standard HDF5 but it is also compatible with NetCDF 4 readers: in most cases one needs to specify only the variable or group name to read the data. The HDF5 and NetCDF libraries provide useful command line tools, which can be used to gather information about the RH 1.5D files or extract data. Additionally, there is a more complete set of tools written in Python to read and analyse these files.</p> <p>Warning</p> <p>Because of the limitations of different languages, not all interfaces support all HDF5 features. Some libraries (e.g. IDL or plain h5py in Python) will not detect missing data in arrays (written with the fill value). In such cases, reading variables with missing data, the data are read with no warning or indication of those that have special fill values.</p> <p>The structure of the three output files is given below.</p> <p>Missing data</p> <p>When a column fails to converge, output for that column is not written. This means that the variables that depend on <code>(nx, ny)</code> will have some values missing. HDF5 marks these values as missing data and uses a fill value (of 9.9692e+36). When the <code>15D_DEPTH_ZCUT</code> option is used, not all heights will be used in the calculation. The code does not read the skipped parts of the atmosphere. When writing such variables of <code>nz</code>, only the points that were used are written to the file, and the rest will be marked as missing data (typically the z cut height varies with the column).</p>"},{"location":"output/#output_auxhdf5","title":"<code>output_aux.hdf5</code>","text":"<p>This file contains the level populations and radiative rates. For each active atom or molecule, it contains different groups called <code>atom_XX</code> or <code>molecule_XX</code>, where <code>XX</code> is the identifier for the species (e.g. <code>MG</code>, <code>CO</code>).</p> <p>Note</p> <p>The atmosphere dimensions on many of the output files are not necessarily the same as in the atmosphere file. They depend on the number of columns calculated, which are a function of <code>X/Y_START/END/STEP</code>.</p> <p>It has the following global attributes:</p> <code>atmosID</code> Identifier for the atmosphere file. <code>rev_id</code> Revision identifier. <code>nx</code> Number of points in x dimension <code>ny</code> Number of points in y dimension <code>nz</code> Number of points in height dimension <p>Inside each of the atom/molecule groups, the following dimensions can exist:</p> Name Description <code>x</code> Horizontal x dimension. <code>y</code> Horizontal y dimension. <code>height</code> Vertical dimension. <code>level</code> Number of atomic levels. <code>line</code> Number of atomic transitions <code>continuum</code> Number of bound-free transitions. <code>vibration_level</code> Number of molecule vibration levels. <code>molecular_line</code> Number of molecular lines. <code>rotational_state</code> Number of rotational states. <p>The atom groups can contain the following optional variables:</p> Name Dimensions Description <code>populations</code> <code>(level, x, y, height)</code> Atomic populations. <code>populations_LTE</code> <code>(level, x, y, height)</code> Atomic LTE populations. <code>Rij_line</code> <code>(line, x, y, height)</code> Radiative rates out of the line. <code>Rji_line</code> <code>(line, x, y, height)</code> Radiative rates into the line. <code>Rij_continuum</code> <code>(continuum, x, y, height)</code> Radiative rates out of the bf transition. <code>Rji_continuum</code> <code>(continuum, x, y, height)</code> Radiative rates into the bf transition. <code>collision_rates</code> <code>(level, level, x, y, height)</code> Collisional rates.  Convention: first index is upper level. <p>The molecule groups can contain the following optional variables:</p> Name Dimensions Description <code>populations</code> <code>(vibration_level, x, y, height)</code> Molecular populations. <code>populations_LTE</code> <code>(vibration_level, x, y, height)</code> Molecular LTE populations. <p>All units are SI.</p> <p>Note</p> <p>In older versions it was possible to specify the keyword <code>15D_WRITE_EXTRA</code> and get additional output written to <code>output_aux.hdf5</code> (e.g. a new <code>opacity</code> group and more rates). While the procedures are still in <code>writeAux_p.c</code>, the functionality is deprecated because other changes in the code were not compatible with this way of writing the output. It is possible that this functionality will return at a later version.</p>"},{"location":"output/#output_indatahdf5","title":"<code>output_indata.hdf5</code>","text":"<p>This file contains data and metadata related to the run. It contains three groups: <code>input</code> (mostly settings from <code>keyword.input</code>), <code>atmos</code> (atmospheric variables), and <code>mpi</code> (several variables relating to the run).</p> <p>It has the following global attributes:</p> <code>atmosID</code> Identifier for the atmosphere file. <code>rev_id</code> Revision identifier. <code>nx</code> Number of points in x dimension <code>ny</code> Number of points in y dimension <code>nz</code> Number of points in height dimension <p>The <code>input</code> group contains all the input files (except atmosphere and molecular data), and a few attributes that are options from <code>keyword.input</code>. It contains the following string variables:</p> Variable Description <code>atom_groups</code> Array with names of atom groups. Other is the same as atom order in <code>atoms.input</code> <code>atoms_file_contents</code> Contents of <code>atoms.input</code> saved into a string <code>keyword_file_contents</code> Contents of <code>keyword.input</code> saved into a string <code>kurucz_file contents</code> Contents of <code>kurucz.input</code> saved into a string, only if used <p>The <code>input</code> group also has other groups inside. If Kurucz line lists are used, it contains groups called <code>Kurucz_line_file0</code>, ..., <code>Kurucz_line_fileN</code>, where N-1 is the total number of line list files. The other groups are all atom files (<code>PASSIVE</code> and <code>ACTIVE</code>), and they take the names of <code>atom_XX</code>, where <code>XX</code> is the element name (for a list of these, see the variable <code>atom_groups</code> above). Inside all of these groups (Kurucz and atom) there is one variable, called <code>file_contents</code>, which contains the file saved intro a string and an attribute, called <code>file_name</code>, which contains the file name and path. These input options and files are read instead of the original files when doing a rerun.</p> <p>The <code>atmos</code> groups contains the dimensions <code>x</code>, <code>y</code>, <code>height</code>, <code>element</code> and <code>ray</code>. It also contains the following variables:</p> Name Dimensions Units Description <code>temperature</code> <code>(x, y, height)</code> K Temperatures <code>velocity_z</code> <code>(x, y, height)</code> m s<sup>-1</sup> Vertical velocities <code>electron_density</code> <code>(x, y, height)</code> m<sup>-3</sup> Electron   densities <code>height_scale</code> <code>(x, y, height)</code> m Height scale used. Can be different for every column when depth refine is used. <code>element_weight</code> <code>(element)</code> a.m.u. Atomic weights <code>element_abundance</code> <code>(element)</code> Element abundances relative to hydrogen. <code>muz</code> <code>(ray)</code> mu values for each ray. <code>muz</code> <code>(ray)</code> mu weights for each ray. <code>x</code> <code>(x)</code> m Spatial coordinates along x axis. <code>y</code> <code>(y)</code> m Spatial coordinates along y axis. <p>Note</p> <p>When <code>15D_DEPTH_REFINE</code> is used, each column will have a different (optimised) height scale, but they all have the same number of depth points (<code>nz</code>). In these cases, it is very important to save the <code>height</code> variable because otherwise one does not know how to relate the height relations of quantities from different columns.</p> <p>The <code>atmos</code> group also contains the following attributes:</p> <code>moving</code> Unsigned int, 1 if velocity fields present. <code>stokes</code> Unsigned int, 1 if stokes output present. <p>The <code>mpi</code> group contains the dimensions <code>x</code>, <code>y</code>, and <code>iteration</code> (maximum number of iterations).</p> <p>Warning</p> <p><code>iteration</code> is needs to be hardcoded for reruns. The default maximum value is 1500. If your <code>N_MAX_ITER</code> is larger than this, <code>iteration</code> will be adjusted. Reruns can never have a value larger than the maximum of 1500 or <code>N_MAX_ITER</code> (of the first run).</p> <p>The <code>mpi</code> group also contains several variables:</p> Name Dimensions Description <code>xnum</code> <code>(x)</code> Indices of x positions calculated. <code>xnum</code> <code>(x)</code> Indices of x positions calculated. <code>task_map</code> <code>(x, y)</code> Maps which process ran which column. <code>task_map_number</code> <code>(x, y)</code> Maps which task number each column was. <code>iterations</code> <code>(x, y)</code> Number of iterations used for each column. <code>convergence</code> <code>(x, y)</code> Indicates if each column converged or not. Possible values are <code>1</code> (converged), <code>0</code> (non converged),  or <code>-1</code> (crashed). <code>delta_max</code> <code>(x, y)</code> Final value for <code>delta_max</code> when iteration finished. <code>delta_max_history</code> <code>(x, y, iteration)</code> Evolution of <code>delta_max</code> <code>z_cut</code> <code>(x, y)</code> Height index of the temperature cut. <p>The <code>mpi</code> group also contains the following attributes: <code>x_start</code>, <code>x_end</code>, <code>x_step</code>, <code>y_start</code>, <code>y_end</code>, and <code>y_step</code>, all of which are options from <code>keyword.input</code>.</p>"},{"location":"output/#output_rayhdf5","title":"<code>output_ray.hdf5</code>","text":"<p>This file contains the synthetic spectra and can also contain extra information such as opacities and the source function. It contains only the root group. Its dimensions are <code>x</code>, <code>y</code>, <code>wavelength</code>, and eventually <code>wavelength_selected</code> and <code>height</code>. The latter two are only present when <code>ray.input</code> specifies more than <code>0</code> wavelengths for detailed output, and it matches <code>Nsource</code>, the number of those wavelengths entered in <code>ray.input</code>.</p> <p>It can contain the following variables:</p> Name Dimensions Units Description <code>wavelength</code> <code>(    wavelength)</code> nm Wavelength     scale. <code>intensity</code> <code>(x, y,wavelength)</code> W m<sup>-2</sup> Hz<sup>-1</sup> sr<sup>-1</sup> Synthetic  disk-centre    intensity (Stokes I) <code>stokes_Q</code> <code>(x, y, wavelength)</code> W m<sup>-2</sup> Hz<sup>-1</sup> sr<sup>-1</sup> Stokes Q.  Optional. <code>stokes_U</code> <code>(x, y, wavelength)</code> W m<sup>-2</sup> Hz<sup>-1</sup> sr<sup>-1</sup> Stokes U.  Optional. <code>stokes_V</code> <code>(x, y, wavelength)</code> W m<sup>-2</sup> Hz<sup>-1</sup> sr<sup>-1</sup> Stokes V.  Optional. <code>tau_one_height</code> <code>(x, y,wavelength)</code> m Height where  optical depth reaches unity, for each column. Optional. <code>wavelength_selected</code> <code>(wavelength_selected)</code> Wavelength scale for the detailed  output variables   below.  Optional. <code>wavelength_indices</code> <code>(wavelength_selected)</code> Indices of wavelengths selected for variables below. Optional. <code>chi</code> <code>(x, y, height, wavelength_selected)</code> m<sup>-1</sup> Total opacity (line and continuum) Optional. <code>source_function</code> <code>(x, y, height, wavelength_selected)</code> W m<sup>-2</sup> Hz<sup>-1</sup> sr<sup>-1</sup> Total source function (line and continuum) Optional. <code>Jlambda</code> <code>(x, y, height, wavelength_selected)</code> W m<sup>-2</sup> Hz<sup>-1</sup> sr<sup>-1</sup> Angle-averaged radiation field Optional. <code>scattering</code> <code>(x, y, height, wavelength_selected)</code> Scattering term multiplied by Jlambda Optional. <p>The <code>wavelength</code> is in nm, air or vacuum units, depending if <code>VACUUM_TO_AIR</code> is <code>TRUE</code> or <code>FALSE</code> (in <code>keyword.input</code>). <code>chi</code> is in m<sup>-1</sup> and <code>tau_one_height</code> in m.</p> <p>Despite internally being calculated in double precision, all the output (except the wavelength scale) is written in single precision to save disk space.</p> <p>The full Stokes vector is only written when in <code>keyword.input</code> <code>STOKES_MODE</code> is not <code>NO_STOKES</code> and the <code>STOKES_INPUT</code> is set.</p> <p>The <code>chi</code>, <code>source_function</code>, and <code>Jlambda</code> variables depend on the 3D grid and on wavelength. Therefore, for even moderate grid sizes they can take huge amounts of space. If <code>nx = ny = nz = 512</code> and <code>wavelength_selected = 200</code>, each of these variables will need 100Gb of disk space. For a simulation with a cubic grid of 1024<sup>3</sup> points and saving the full output for 1000 wavelength points, <code>output_ray.hdf5</code> will occupy a whopping 12Tb per snapshot of disk space. To avoid such problems, these large arrays are only written when <code>ray.input</code> contains <code>Nsource &gt; 0</code>, and for the wavelengths selected.</p> <p>The <code>output_ray.hdf5</code> file contains the following global attributes:</p> <code>atmosID</code> Identifier for the atmosphere file <code>snapshot_number</code> Number of simulation snapshot (from atmosphere file) <code>rev_id</code> Revision identifier <code>nx</code> Number of points in x dimension <code>ny</code> Number of points in y dimension <code>nz</code> Number of points in height dimension <code>nwave</code> Number of wavelength points <code>wavelength_selected</code> Number of wavelength points selected for detailed output <code>creation_time</code> Local time when file was created"},{"location":"output_idl/","title":"Reading output in IDL","text":"<p>There are no specific IDL routines for reading the output from RH 1.5D. However, there is a utility function that can be used to variables from HDF5/netCDF4 files, under the <code>idl/</code> directory in a file named <code>read_ncdf_var.pro</code>. The function <code>read_ncdf_var()</code> can be used to read variables from an HDF5 or netCDF4 file, e.g.:</p> <pre><code>IDL&gt; data = read_ncdf_var(\"output_ray.hdf5\", \"intensity\")\nIDL&gt; help, data\nDATA            FLOAT     = Array[902, 512, 512]\nIDL&gt; pops = read_ncdf_var(\"output_aux.hdf5\", \"populations\", groupname=\"atom_CA\")\nIDL&gt; help, pops\nPOPS            FLOAT     = Array[400, 512, 512, 5]\n</code></pre> <p>Note</p> <p>The IDL analysis suite of RH does not work with RH 1.5D.</p>"},{"location":"output_python/","title":"Reading output in Python","text":"<p>The helita package has a complete python interface to read the output, input, and visualise files from RH 1.5D. The <code>helita</code> tools are described in detail in section helita.</p> <p>If <code>helita</code> is not available, the easiest and fastest way to read the RH 1.5D output (or input) files in Python is via the xarray package. <code>xarray</code> can load the output files as a dataset directly, but in the case of the <code>output_aux.hdf5</code> and <code>output_indata.hdf5</code> one needs to specify which group to read (see above).</p> <p>Here is a quick example on how to read some output from RH 1.5D with <code>xarray</code>:</p> <pre><code>&gt;&gt;&gt; import xarray\n&gt;&gt;&gt; ray = xarray.open_dataset(\"output_ray.hdf5\")\n&gt;&gt;&gt; ray\n&lt;xarray.Dataset&gt;\nDimensions:              (height: 82, wavelength: 902, wavelength_selected: 10, x: 1, y: 1)\nCoordinates:\n  * wavelength           (wavelength) float64 28.0 31.4 32.8 33.7 34.3 35.3 ...\n  * wavelength_selected  (wavelength_selected) float64 85.1 276.4 278.5\n  * x                    (x) float64 0.0\n  * y                    (y) float64 0.0\nDimensions without coordinates: height\nData variables:\n    Jlambda              (x, y, height, wavelength_selected) float64 ...\n    chi                  (x, y, height, wavelength_selected) float64 ...\n    intensity            (x, y, wavelength) float64 ...\n    scattering           (x, y, height, wavelength_selected) float64 ...\n    source_function      (x, y, height, wavelength_selected) float64 ...\n    wavelength_indices   (wavelength_selected) int32 ...\nAttributes:\n    atmosID:              FALC_82_5x5.hdf5 (Wed Jan 10 15:29:28 2018)\n    snapshot_number:      0\n    rev_id:               001d537  Tiago Pereira  2018-01-10 12:34:07 +0100\n    nx:                   1\n    ny:                   1\n    nz:                   82\n    nwave:                902\n    wavelength_selected:  3\n    creation_time:        2018-01-10T16:16:42+0100\n&gt;&gt;&gt; aux = xarray.open_dataset(\"output_aux.hdf5\", group=\"atom_MG\")\n&gt;&gt;&gt; aux\n&lt;xarray.Dataset&gt;\nDimensions:          (continuum: 10, height: 82, level: 11, line: 15, x: 1, y: 1)\nCoordinates:\n  * x                (x) float64 0.0\n  * y                (y) float64 0.0\nDimensions without coordinates: continuum, height, level, line\nData variables:\n    Rij_continuum    (continuum, x, y, height) float64 ...\n    Rij_line         (line, x, y, height) float64 ...\n    Rji_continuum    (continuum, x, y, height) float64 ...\n    Rji_line         (line, x, y, height) float64 ...\n    populations      (level, x, y, height) float64 ...\n    populations_LTE  (level, x, y, height) float64 ...\nAttributes:\n    nlevel:      11\n    nline:       15\n    ncontinuum:  10\n</code></pre>"},{"location":"running/","title":"Running the code","text":""},{"location":"running/#binaries-label","title":"Binaries and execution","text":"<p>Compilation should produce three executables: <code>rh15d_ray_pool</code>, <code>rh15d_ray</code>, and <code>rh15d_lteray</code>. The latter is a special case for running only in LTE. The other two are the main programs. They represent two different modes of job distribution: normal and pool.</p> <p>In the pool mode there is a process that works as overlord: its function is to distribute the work to other processes. The other processes (drones) ask the overlord for a work unit. When they finish their unit, they go back and ask for more, until all tasks are completed. Because of race conditions and because different columns will run at different speeds, it is not possible to know which columns a given process will run beforehand. Due to the overlord, <code>rh15d_ray_pool</code> needs to run with two or more processes. The advantage of the pool mode is that the dynamic load allocation ensures the most efficient use of the resources. With the normal mode it may happen that some processors will work on columns that take longer to converge (especially as they are adjacent), and in the end the execution will have to wait for the process that takes longer. In some cases (especially with PRD) the pool mode can be 2-3 times faster than the normal mode. When one runs with a large number of processes (&gt; 2000) and each column takes little time to calculate, the pool mode can suffer from communication bottlenecks and may be slower because a single overlord cannot distribute the tasks fast enough. The only disadvantage of the pool mode (so far) is that not all output is currently supported with this mode.</p> <p>Warning</p> <p>The normal mode is deprecated and will be removed in a later revision. Use only for single processor runs or if you know what you're doing!</p> <p>In the normal mode the jobs (all the atmosphere columns for which one wants to calculate) are divided by the number of processes at the start of the execution. There is no communication between processes, and each process knows from the start all the columns it is going to run. These columns are adjacent. If the number of columns is not a multiple of the number of processes, there will be some processes with larger workloads. There is no minimum number of processes to run, and <code>rh15d_ray</code> can also be run in a single process. Regions of an atmosphere can take a lot longer to run than others, and the processes that work on those will take longer to finish. In the normal mode this means that the slowest process will set the overall running time, and therefore in practice it can take more than 10x longer than the pool mode (and is therefore not recommended).</p> <p>As an MPI program, the binaries should be launched with the appropriate command. Some examples:</p> <pre><code>mpirun -np N ./rh15d_ray_pool\nsrun ./rh15d_ray_pool       # Use in Betzy or other system with SLURM\nmpiexec ./rh15d_ray_pool    # use in Pleiades\naprun -B ./rh15d_ray        # use in Hexagon or other Cray\n</code></pre>"},{"location":"running/#the-run-directory","title":"The run directory","text":"<p>Warning</p> <p>Before running, make sure you have the sub-directories <code>scratch</code> and</p> <p><code>output</code> in the run directory.</p> <p>The run directory contains the configuration files, the binaries, and the <code>scratch</code> and <code>output</code> directories. As the names imply, temporary files will be placed under <code>scratch</code> and the final output files in <code>output</code>. No files under <code>scratch</code> will be used after the run is finished (they are not read for re-runs).</p> <p>The <code>scratch</code> directory contains different types of files. Most of them are binary files write by RH 1.5D to save memory. Example files are the <code>background_p*.dat</code> with the background opacities, files with PRD weights, and the <code>rh_p*.log</code> log files. Each process creates one of those files, and they will have the suffix <code>_pN.*</code>, where <code>N</code> is the process number. The log files have the same format as in RH. The writing of each process's log file is buffered by line. Because these are updated often, when running with many processes this can be a drag on some systems. Therefore, it is possible to run full buffering (meaning log files are only written when the main program finishes). This option is not exposed in the configuration files, so one needs to change the file <code>parallel.c</code> in the following part:</p> <pre><code>/* _IOFBF for full buffering, _IOLBF for line buffering */\nsetvbuf(mpi.logfile, NULL, _IOLBF, BUFSIZ_MPILOG);\n</code></pre> <p>One should replace <code>_IOLBF</code> by <code>_IOFBF</code> to change from line buffering to full buffering.</p> <p>The <code>output</code> directory will contain the three output files: <code>output_aux.hdf5</code>, <code>output_indata.hdf5</code>, and <code>output_ray.hdf5</code>. See output for more details on the structure of these files. If doing a re-run, these files must already exist; they will be updated with the new results. Otherwise, if these files are already in <code>output</code> before the execution, they will be overwritten. At the start of the execution, the output files are written with a special a fill value. This means that the disk space for the full output must be available at the start of the run, and no CPU time will be wasted if at the end of the run there is not enough disk space. The files are usually written every time a process finishes work on a given column. The fill value arrays are overwritten with the data. One advantage of this method is that even if the system crashes or the program stops, it is possible to recover the results already written (and a re-run can be performed for just the missing columns).</p> <p>All the processes write asynchronously to all the output files. In some cases this can cause contention in the filesystem, with many processes trying to access the same data at the same time. In the worst case scenario, the contention can create bottlenecks which practically stop the execution. Therefore, it is highly recommended that the users tune their filesystem for the typical loads of RH. Many supercomputers make use of Lustre, a parallel filesystem. With Lustre, resources such as files can be divided in different stripes that can be placed in several different machines (OSTs). For running RH with more than 500 processes, one should use as many OSTs as available in the system, and select the lustre stripe size to the typical amount of data written to a file per simulation column. The stripe can set with the <code>lfs setstripe</code> command:</p> <pre><code>lfs setstripe -s stripe_size -c stripe_count -o stripe_offset directory|filename\n</code></pre> <p>It can be run per file (e.g. <code>output_ray.hdf5</code>), or for the whole <code>output</code> directory. Using a stripe count of <code>-1</code> will ensure that the maximum number of OSTs is used. For the typical files RH 1.5D produces, it is usually ok to apply the same Lustre settings to the whole <code>output</code> directory, and the following settings seem to reasonable (tested on Betzy and Pleiades):</p> <pre><code>lfs setstripe -S 8M -c -1 output/\n</code></pre> <p>Similarly, the directory where you will store the input atmospheres, and the <code>scratch</code> directory can also benefit from Lustre striping. For <code>scratch</code>, because most files there are small, it is recommended to use a stripe count of 1.</p> <p>Info</p> <p>You need a parallel filesystem if you are running RH 1.5D across more than one host. Most supercomputers have parallel filesystems, but if you are running in a smaller cluster this may not be the case. RH 1.5D will always run, but the HDF5 writes will not work and the results will be unreadable. NFS is not a parallel file system.</p>"},{"location":"running/#logs-and-messages","title":"Logs and messages","text":"<p>In addition to the logs per process saved to <code>scratch</code>, a much smaller log will be printed in <code>stdout</code>. This log is a smaller summary of what each process is doing. Here is an example of typical messages:</p> <pre><code>Process   1: --- START task   1, (xi,yi) = (  0,156)\nProcess 232: --- START task   1, (xi,yi) = (  0,159)\nProcess  36: --- START task   1, (xi,yi) = (  0,162)\nProcess  12: --- START task   1, (xi,yi) = (  0,171)\n(...)\nProcess  12: *** END   task   1 iter, iterations = 121, CONVERGED\nProcess   3: *** END   task   1 iter, iterations = 200, NO Convergence\nProcess   4: *** SKIP  task   1 (crashed after 81 iterations)\nProcess   3: --- START task   2, (xi,yi) = ( 23, 64)\nProcess  12: --- START task   2, (xi,yi) = ( 23, 65)\nProcess   4: --- START task   2, (xi,yi) = ( 23, 65)\n(...)\n*** Job ending. Total 262144 1-D columns: 262142 converged, 1 did not converge, 1 crashed.\n*** RH finished gracefully.\n</code></pre> <p>In this example one can see the three possible outputs for a single-column calculation: convergence, non-convergence (meaning the target <code>ITER_LIMIT</code> was not met in <code>N_MAX_ITER</code> iterations), or a crash (many reasons). If there are singular matrices or other causes for a column to crash, RH 1.5D will skip that column and proceed to the next work unit. Such cases can be re-run with different parameters. In some cases (e.g. inexistent files) it is not possible to prevent a crash, and RH 1.5D will finish non-gracefully.</p>"},{"location":"running/#reruns-and-lack-of-convergence","title":"Reruns and lack of convergence","text":"<p>Dynamic atmospheres often have large gradients in temperature, density, velocity, etc. that cause problems when solving the non-LTE problem. This may lead to some (or all) columns not converging, and is dependent on the input atmosphere, model atoms, and run options. In RH terms, non-converged or \"crashed\", represent the same problem. In some cases, the iterations diverge strongly (crash), while in others they fail to reach the target limit for convergence in the allocated maximum number of iterations (non-convergence).</p> <p>The output for atmosphere columns that did not converged or crashed is not saved to disk (a fill value is used instead). The recommended procedure in these cases is to rerun RH with different input options (e.g. less agressive acceleration, a larger number of maximum iterations). A special rerun mode is available to save time calculating again the columns that have already converged. When <code>15D_RERUN = TRUE</code> in <code>keyword.input</code>, RH will read the output and run again only for the columns that did not converge.</p> <p>The rerun mode requires all the previous output to be under <code>output/</code>. The user has the possibility of changing options in <code>keyword.input</code> for the rerun. Not all options can be changed, because this could lead to non-sensical results (e.g. changing the input atmosphere or atom files). Only the following options can be changed in <code>keyword.input</code>:</p> <code>15D_RERUN</code> <code>15D_DEPTH_CUT</code> <code>15D_TMAX_CUT</code> <code>15D_DEPTH_REFINE</code> <code>N_PESC_ITER</code> <code>COLLRAD_SWITCH</code> <code>COLLRAD_SWITCH_INIT</code> <code>PRD_SWITCH</code> <code>NRAYS</code> <code>N_MAX_SCATTER</code> <code>N_MAX_ITER</code> <code>ITER_LIMIT</code> <code>NG_DELAY</code> <code>NG_ORDER</code> <code>NG_PERIOD</code> <code>S_INTERPOLATION</code> <code>PRD_N_MAX_ITER</code> <code>PRD_ITER_LIMIT</code> <code>B_STRENGTH_CHAR</code> <p>All the other options are locked to the values used for the firs run. Likewise, it is not possible to change <code>atoms.input</code>, the atom files, or the line list files. When RH 1.5D is first run, nearly all input options (except the input atmosphere and molecule files) are saved into the output, and in a rerun these are read from the output and not from the original files. This also means that a rerun can be performed even if the original files are no longer available.</p>"},{"location":"running/#helper-script","title":"Helper script","text":"<p>There is a Python script called <code>runtools.py</code> designed to make it easier to run RH 1.5D for large projects. It resides in <code>rh/python/runtools.py</code>. It requires Python with the numpy and h5py (or netCDF4) modules. It was made to run a given RH 1.5D setup over many simulation snapshots, spanning several atmosphere files. It supports a progressive rerun of a given problem, and allows the of use different <code>keyword.input</code> parameters for different columns, tackling columns harder to converge.</p> <p>The first part of <code>runtools.py</code> should be modified for a users's need. It typically contains:</p> <pre><code>atmos_dir = '/mydata_dir'\nseq_file = 'RH_SEQUENCE'\noutsuff = 'output/output_ray_mysim_CaII_PRD_s%03i.hdf5'\nmpicmd = 'mpiexec'\nbin = './rh15d_ray_pool'\ndefkey = 'keyword.save'\nlog = 'rh_running.log'\ntm = 40\nrerun = True\nrerun_opt = [ {'NG_DELAY': 60, 'NG_PERIOD': 40, '15D_DEPTH_REFINE': 'FALSE',\n               '15D_ZCUT': 'TRUE', 'N_MAX_ITER': 250, 'PRD_SWITCH': 0.002 },\n              {'NG_DELAY': 120, 'NG_PERIOD': 100, '15D_DEPTH_REFINE': 'TRUE',\n               'PRD_SWITCH': 0.001 } ]\n</code></pre> <p>The different options are:</p> Name Type Description <code>atmos_dir</code> string Directory where the atmosphere files are kept. <code>seq_file</code> string Location of sequence file. This file contains the names of the atmosphere files to be used (one file per line). The script will then run RH 1.5D for every snapshot in every file listed. <code>outsuff</code> string Template to write the <code>output_ray.ncdf</code> files. The <code>%03i</code> format will be replaced with the snapshot number. <code>mpicmd</code> string System-dependent command to launch MPI. The script knows that for aprun the -B option should be used. This option also activates system specific routines (e.g. how to kill the run in pleiades). <code>bin</code> string RH 1.5D binary to use. <code>defkey</code> string Default template for <code>keyword.input</code>. Because the of the rerun options, <code>keyword.input</code> is overwritten for every rerun. This file is used as a template it (i.e., most of its options will be unchanged, unless specified in <code>rerun_opt</code>). <code>log</code> string File where to save the main log. Will be overwritten for each new snapshot. <code>tm</code> int Timeout (in minutes) to kill execution of code, if there is no message written to main log. Used to prevent code from hanging if there are system issues. After killed, program is relaunched. If <code>tm = 0</code>, program will never be killed. <code>rerun</code> bool If <code>True</code>, will re-run the program (with different settings) to achieve convergence if any columns failed. Number of reruns is given by size of <code>rerun_opt</code>. <code>rerun_opt</code> list Options for re-run. This is a list made of dictionaries. Each dictionary contains the keywords to update <code>keyword.input</code>. Only the keywords that differ from the <code>defkey</code> file are necessary. <p>Info</p> <p>Only the first line of the sequence time is read at a time. The script reads the first line, deletes it from the file, and closes the file. It then reads the first line again and continues running, until there are no more lines in the file. This behaviour enables the file to be worked by multiple scripts at the same time, and allows one to dynamically change the task list at any time of the run.</p> <p>Info</p> <p>The script also includes a tenaciously persistent wait and relaunch feature designed to avoid corruption if there are system crashes or problems. Besides the <code>tm</code> timeout, if there is any problem with the execution, the code will wait for some periods and try and relaunch the code. For example, if one of the atmosphere files does not exist, <code>runtools.py</code> will try three times and then proceed to the next file.</p>"}]}